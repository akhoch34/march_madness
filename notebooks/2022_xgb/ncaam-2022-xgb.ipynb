{"cells":[{"cell_type":"markdown","metadata":{},"source":["# NCAAM 2022 - XGB w/ FE on three Datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import seaborn as sns; sns.set()\n","\n","DATA_DIR = '../../data/2022'\n","\n","STAGE_1 = False # This needs to be False when it's stage 2 "]},{"cell_type":"markdown","metadata":{},"source":["## FE on RegularSeasonCompactResults\n","\n","### Calculating Win %"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["MRSCResults = pd.read_csv(DATA_DIR + '/MRegularSeasonCompactResults.csv')\n","\n","A_w = MRSCResults[MRSCResults.WLoc == 'A']\\\n","    .groupby(['Season','WTeamID'])['WTeamID'].count().to_frame()\\\n","    .rename(columns={\"WTeamID\": \"win_A\"})\n","N_w = MRSCResults[MRSCResults.WLoc == 'N']\\\n","    .groupby(['Season','WTeamID'])['WTeamID'].count().to_frame()\\\n","    .rename(columns={\"WTeamID\": \"win_N\"})\n","H_w = MRSCResults[MRSCResults.WLoc == 'H']\\\n","    .groupby(['Season','WTeamID'])['WTeamID'].count().to_frame()\\\n","    .rename(columns={\"WTeamID\": \"win_H\"})\n","win = A_w.join(N_w, how='outer').join(H_w, how='outer').fillna(0)\n","\n","H_l = MRSCResults[MRSCResults.WLoc == 'A']\\\n","    .groupby(['Season','LTeamID'])['LTeamID'].count().to_frame()\\\n","    .rename(columns={\"LTeamID\": \"lost_H\"})\n","N_l = MRSCResults[MRSCResults.WLoc == 'N']\\\n","    .groupby(['Season','LTeamID'])['LTeamID'].count().to_frame()\\\n","    .rename(columns={\"LTeamID\": \"lost_N\"})\n","A_l = MRSCResults[MRSCResults.WLoc == 'H']\\\n","    .groupby(['Season','LTeamID'])['LTeamID'].count().to_frame()\\\n","    .rename(columns={\"LTeamID\": \"lost_A\"})\n","lost = A_l.join(N_l, how='outer').join(H_l, how='outer').fillna(0)\n","\n","win.index = win.index.rename(['Season', 'TeamID'])\n","lost.index = lost.index.rename(['Season', 'TeamID'])\n","wl = win.join(lost, how='outer').reset_index()\n","wl['win_pct_A'] = wl['win_A'] / (wl['win_A'] + wl['lost_A'])\n","wl['win_pct_N'] = wl['win_N'] / (wl['win_N'] + wl['lost_N'])\n","wl['win_pct_H'] = wl['win_H'] / (wl['win_H'] + wl['lost_H'])\n","wl['win_pct_All'] = (wl['win_A'] + wl['win_N'] + wl['win_H']) / \\\n","    (wl['win_A'] + wl['win_N'] + wl['win_H'] + wl['lost_A']\\\n","     + wl['lost_N'] + wl['lost_H'])\n","\n","del A_w, N_w, H_w, H_l, N_l, A_l, win, lost"]},{"cell_type":"markdown","metadata":{},"source":["### Creating Score Features"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["MRSCResults['relScore'] = MRSCResults.WScore - MRSCResults.LScore\n","\n","w_scr = MRSCResults.loc[:, ['Season', 'WTeamID', 'WScore', 'WLoc','relScore']]\n","w_scr.columns = ['Season', 'TeamID','Score','Loc','relScore']\n","l_scr = MRSCResults.loc[:, ['Season', 'LTeamID', 'LScore', 'WLoc','relScore']]\n","l_scr['WLoc'] = l_scr.WLoc.apply(lambda x: 'H' if x == 'A' else 'A' \\\n","                                 if x == 'H' else 'N')\n","l_scr['relScore'] = -1 * l_scr.relScore \n","l_scr.columns = ['Season', 'TeamID','Score','Loc','relScore']\n","wl_scr = pd.concat([w_scr,l_scr])\n","\n","A_scr = wl_scr[wl_scr.Loc == 'A'].groupby(['Season','TeamID'])\\\n","        ['Score','relScore'].mean()\\\n","        .rename(columns={\"Score\": \"Score_A\", \"relScore\": \"relScore_A\"})\n","N_scr = wl_scr[wl_scr.Loc == 'N'].groupby(['Season','TeamID'])\\\n","        ['Score','relScore'].mean()\\\n","        .rename(columns={\"Score\": \"Score_N\", \"relScore\": \"relScore_N\"})\n","H_scr = wl_scr[wl_scr.Loc == 'H'].groupby(['Season','TeamID'])\\\n","        ['Score','relScore'].mean()\\\n","        .rename(columns={\"Score\": \"Score_H\", \"relScore\": \"relScore_H\"})\n","All_scr = wl_scr.groupby(['Season','TeamID'])['Score','relScore']\\\n","    .mean().rename(columns={\"Score\": \"Score_All\", \"relScore\": \"relScore_All\"})\n","scr = A_scr.join(N_scr, how='outer').join(H_scr, how='outer')\\\n","    .join(All_scr, how='outer').fillna(0).reset_index()\n","\n","del w_scr, l_scr, wl_scr, A_scr, H_scr, N_scr, All_scr"]},{"cell_type":"markdown","metadata":{},"source":["## FE on MRegularSeasonDetailedResults"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["MRSDetailedResults = pd.read_csv(DATA_DIR + '/MRegularSeasonDetailedResults.csv')\n","\n","w = MRSDetailedResults.loc[:, ['Season', 'WTeamID', 'WFGM','WFGA','WFGM3'\n","                               ,'WFGA3','WFTM','WFTA','WOR','WDR','WAst',\n","                               'WTO','WStl','WBlk','WPF']]\n","w.columns = ['Season', 'TeamID', 'FGM','FGA','FGM3','FGA3','FTM','FTA','OR','DR',\n","             'Ast','TO','Stl','Blk','PF']\n","l = MRSDetailedResults.loc[:, ['Season', 'LTeamID', 'LFGM','LFGA','LFGM3',\n","                               'LFGA3','LFTM','LFTA','LOR','LDR','LAst',\n","                               'LTO','LStl','LBlk','LPF']]\n","l.columns = ['Season', 'TeamID', 'FGM','FGA','FGM3','FGA3','FTM','FTA','OR','DR',\n","             'Ast','TO','Stl','Blk','PF']\n","\n","detail = pd.concat([w,l])\n","detail['goal_rate'] = detail.FGM / detail.FGA \n","detail['3p_goal_rate'] = detail.FGM3 / detail.FGA3  \n","detail['ft_goal_rate'] = detail.FTM  / detail.FTA  \n","\n","dt = detail.groupby(['Season','TeamID'])['FGM','FGA','FGM3','FGA3','FTM','FTA',\n","                                         'OR','DR','Ast','TO','Stl','Blk','PF',\n","                                          'goal_rate', '3p_goal_rate',\n","                                         'ft_goal_rate']\\\n","                                        .mean().fillna(0).reset_index()\n","\n","del w, l, detail"]},{"cell_type":"markdown","metadata":{},"source":["## FE on MMasseyOrdinals\n","\n","Using only MOR for now."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["MMOrdinals = pd.read_csv(DATA_DIR + '/MMasseyOrdinals.csv')\n","\n","MOR_127_128 = MMOrdinals[(MMOrdinals.SystemName == 'MOR') & \\\n","                ((MMOrdinals.RankingDayNum == 127) \\\n","                 | (MMOrdinals.RankingDayNum == 128))]\\\n","                [['Season','TeamID','OrdinalRank']]\n","MOR_50_51 = MMOrdinals[(MMOrdinals.SystemName == 'MOR') & \\\n","                ((MMOrdinals.RankingDayNum == 50) \\\n","                 | (MMOrdinals.RankingDayNum == 51))]\\\n","                [['Season','TeamID','OrdinalRank']]\n","MOR_15_16 = MMOrdinals[(MMOrdinals.SystemName == 'MOR') & \\\n","                ((MMOrdinals.RankingDayNum == 15) \\\n","                 | (MMOrdinals.RankingDayNum == 16))]\\\n","                [['Season','TeamID','OrdinalRank']]\n","\n","MOR_127_128 = MOR_127_128.rename(columns={'OrdinalRank':'OrdinalRank_127_128'})\n","MOR_50_51 = MOR_50_51.rename(columns={'OrdinalRank':'OrdinalRank_50_51'})\n","MOR_15_16 = MOR_15_16.rename(columns={'OrdinalRank':'OrdinalRank_15_16'})\n","\n","MOR = MOR_127_128.merge(MOR_50_51, how='left', on=['Season','TeamID'])\\\n","        .merge(MOR_15_16, how='left', on=['Season','TeamID'])\n","\n","## normalizing Rank values by its season maxium as it varies by seasons\n","MOR_max = MOR.groupby('Season')['OrdinalRank_127_128','OrdinalRank_50_51',\n","                                'OrdinalRank_15_16'].max().reset_index()\n","MOR_max.columns = ['Season', 'maxRank_127_128', 'maxRank_50_51', 'maxRank_15_16']\n","\n","MOR_tmp = MMOrdinals[(MMOrdinals.SystemName == 'MOR') \\\n","                     & (MMOrdinals.RankingDayNum < 133)]\n","MOR_stats = MOR_tmp.groupby(['Season','TeamID'])['OrdinalRank']\\\n","            .agg(['max','min','std','mean']).reset_index()\n","MOR_stats.columns = ['Season','TeamID','RankMax','RankMin','RankStd','RankMean']\n","\n","MOR = MOR.merge(MOR_max, how='left', on='Season')\\\n","        .merge(MOR_stats, how='left', on=['Season','TeamID'])\n","MOR['OrdinalRank_127_128'] = MOR['OrdinalRank_127_128'] / MOR['maxRank_127_128']\n","MOR['OrdinalRank_50_51'] = MOR['OrdinalRank_50_51'] / MOR['maxRank_50_51']\n","MOR['OrdinalRank_15_16'] = MOR['OrdinalRank_15_16'] / MOR['maxRank_15_16']\n","MOR['RankTrans_50_51_to_127_128'] = MOR['OrdinalRank_127_128'] \\\n","                                    - MOR['OrdinalRank_50_51']\n","MOR['RankTrans_15_16_to_127_128'] = MOR['OrdinalRank_127_128'] \\\n","                                    - MOR['OrdinalRank_15_16']\n","\n","# MOR['RankMax'] = MOR['RankMax'] / MOR['maxRank_127_128']\n","# MOR['RankMin'] = MOR['RankMin'] / MOR['maxRank_127_128']\n","# MOR['RankStd'] = MOR['RankStd'] / MOR['maxRank_127_128']\n","# MOR['RankMean'] = MOR['RankMean'] / MOR['maxRank_127_128']\n","\n","MOR.drop(['OrdinalRank_50_51','OrdinalRank_15_16', 'maxRank_50_51'\n","          ,'maxRank_15_16'],axis=1, inplace=True)\n","\n","del MOR_127_128, MOR_50_51, MOR_15_16, MOR_max, MOR_tmp, MOR_stats"]},{"cell_type":"markdown","metadata":{},"source":["Duplicating each data with changing column names to be matched to 'WTeamID' and 'LTeamID' in Tourney dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["wl_1 = wl.loc[:,['Season','TeamID','win_pct_A','win_pct_N',\n","                 'win_pct_H','win_pct_All']]\n","wl_1.columns = [str(col) + '_1' if col not in ['Season','TeamID'] \\\n","                else str(col) for col in wl_1.columns ]\n","\n","wl_2 = wl.loc[:,['Season','TeamID','win_pct_A','win_pct_N',\n","                 'win_pct_H','win_pct_All']]\n","wl_2.columns = [str(col) + '_2' if col not in ['Season','TeamID'] \\\n","                else str(col) for col in wl_2.columns ]\n","\n","scr_1 = scr.copy()\n","scr_1.columns = [str(col) + '_1' if col not in ['Season','TeamID'] \\\n","                 else str(col) for col in scr_1.columns ]\n","\n","scr_2 = scr.copy()\n","scr_2.columns = [str(col) + '_2' if col not in ['Season','TeamID'] \\\n","                 else str(col) for col in scr_2.columns ]\n","\n","dt_1 = dt.copy()\n","dt_1.columns = [str(col) + '_1' if col not in ['Season','TeamID'] \\\n","                else str(col) for col in dt_1.columns ]\n","\n","dt_2 = dt.copy()\n","dt_2.columns = [str(col) + '_2' if col not in ['Season','TeamID'] \\\n","                else str(col) for col in dt_2.columns ]\n","\n","MOR_1 = MOR.copy()\n","MOR_1.columns = [str(col) + '_1' if col not in ['Season','TeamID'] \\\n","                 else str(col) for col in MOR_1.columns ]\n","\n","MOR_2 = MOR.copy()\n","MOR_2.columns = [str(col) + '_2' if col not in ['Season','TeamID'] \\\n","                 else str(col) for col in MOR_2.columns ]"]},{"cell_type":"markdown","metadata":{},"source":["## Loading MNCAATourneyCompactResults\n","\n","This dataset will be the base dataset for the model training"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["TCResults = pd.read_csv(DATA_DIR + '/MNCAATourneyCompactResults.csv')\n","\n","tourney1 = TCResults.loc[:, ['Season','WTeamID','LTeamID']]\n","tourney1.columns = ['Season','TeamID1','TeamID2']\n","tourney1['result'] = 1\n","\n","tourney2 = TCResults.loc[:, ['Season','LTeamID','WTeamID']]\n","tourney2.columns = ['Season','TeamID1','TeamID2']\n","tourney2['result'] = 0\n","\n","tourney = pd.concat([tourney1, tourney2])\n","del tourney1, tourney2"]},{"cell_type":"markdown","metadata":{},"source":["### Merging engineered features to Tourney dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def merge_data(df):\n","\n","    df = df.merge(wl_1, how='left', left_on=['Season','TeamID1'],\n","                  right_on=['Season','TeamID'])\n","    df = df.merge(wl_2, how='left', left_on=['Season','TeamID2'],\n","                  right_on=['Season','TeamID'])\n","    df = df.drop(['TeamID_x','TeamID_y'], axis=1)\n","\n","\n","    df = df.merge(scr_1, how='left', left_on=['Season','TeamID1'],\n","                  right_on=['Season','TeamID'])\n","    df = df.merge(scr_2, how='left', left_on=['Season','TeamID2'],\n","                  right_on=['Season','TeamID'])\n","    df = df.drop(['TeamID_x','TeamID_y'], axis=1)\n","\n","    # df['win_pct_A_diff'] = df['win_pct_A_1'] - df['win_pct_A_2']\n","    # df['win_pct_N_diff'] = df['win_pct_N_1'] - df['win_pct_N_2']\n","    # df['win_pct_H_diff'] = df['win_pct_H_1'] - df['win_pct_H_2']\n","#     df['win_pct_All_diff'] = df['win_pct_All_1'] - df['win_pct_All_2']\n","\n","    # df['Score_A_diff'] = df['Score_A_1'] - df['Score_A_2']\n","    # df['Score_N_diff'] = df['Score_N_1'] - df['Score_N_2']\n","    # df['Score_H_diff'] = df['Score_H_1'] - df['Score_H_2']\n","    # df['Score_All_diff'] = df['Score_All_1'] - df['Score_All_2']\n","\n","    # df['relScore_A_diff'] = df['relScore_A_1'] - df['relScore_A_2']\n","    # df['relScore_N_diff'] = df['relScore_N_1'] - df['relScore_N_2']\n","    # df['relScore_H_diff'] = df['relScore_H_1'] - df['relScore_H_2']\n","#     df['relScore_All_diff'] = df['relScore_All_1'] - df['relScore_All_2']\n","\n","    df = df.merge(dt_1, how='left', left_on=['Season','TeamID1'],\n","                  right_on=['Season','TeamID'])\n","    df = df.merge(dt_2, how='left', left_on=['Season','TeamID2'],\n","                  right_on=['Season','TeamID'])\n","    \n","    df = df.drop(['TeamID_x','TeamID_y'], axis=1)\n","\n","    df = df.merge(MOR_1, how='left', left_on=['Season','TeamID1'],\n","                  right_on=['Season','TeamID'])\n","    df = df.merge(MOR_2, how='left', left_on=['Season','TeamID2'],\n","                  right_on=['Season','TeamID'])\n","    df = df.drop(['TeamID_x','TeamID_y'], axis=1)\n","\n","    df['OrdinalRank_127_128_diff'] = df['OrdinalRank_127_128_1'] \\\n","        - df['OrdinalRank_127_128_2']\n","    \n","    df['magic1'] = df['OrdinalRank_127_128_diff'] - df['RankMean_1']\n","    df['magic2'] = df['RankMean_1'] - df['RankMean_2']\n","    df['magic3'] = df['OrdinalRank_127_128_diff'] - df['RankMean_2']\n","    \n","    df['magic11'] = df['OrdinalRank_127_128_diff'] * df['RankMean_1']\n","    df['magic21'] = df['RankMean_1'] * df['RankMean_2']\n","    df['magic31'] = df['OrdinalRank_127_128_diff'] * df['RankMean_2']\n","    \n","    df['magic12'] = df['OrdinalRank_127_128_diff'] / df['RankMean_1']\n","    df['magic22'] = df['RankMean_1'] / df['RankMean_2']\n","    df['magic32'] = df['OrdinalRank_127_128_diff'] / df['RankMean_2']\n","\n","    df = df.fillna(-1)\n","    \n","    for col in df.columns:\n","        if (df[col] == np.inf).any() or (df[col] == -np.inf).any():\n","            df[col][(df[col] == np.inf) | (df[col] == -np.inf)] = -1\n","    \n","    return df\n","\n","tourney = merge_data(tourney)\n","tourney = tourney.loc[tourney.Season >= 2003,:].reset_index(drop=True)\n","\n","if STAGE_1:\n","    tourney = tourney.loc[tourney.Season < 2015, :]"]},{"cell_type":"markdown","metadata":{},"source":["## Loading Submission Dataset\n","Duplicating each ID with swapping TeamIDs. Predictions will be averaged by ID to get better performance."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["if STAGE_1:\n","    MSampleSubmission = pd.read_csv(DATA_DIR + '/MSampleSubmissionStage1.csv')\n","else:\n","    MSampleSubmission = pd.read_csv(DATA_DIR + '/MSampleSubmissionStage2.csv') # put stage 2 submission file link here\n","\n","test1 = MSampleSubmission.copy()\n","test1['Season'] = test1.ID.apply(lambda x: int(x[0:4]))\n","test1['TeamID1'] = test1.ID.apply(lambda x: int(x[5:9]))\n","test1['TeamID2'] = test1.ID.apply(lambda x: int(x[10:14]))\n","\n","test2 = MSampleSubmission.copy()\n","test2['Season'] = test2.ID.apply(lambda x: int(x[0:4]))\n","test2['TeamID1'] = test2.ID.apply(lambda x: int(x[10:14]))\n","test2['TeamID2'] = test2.ID.apply(lambda x: int(x[5:9]))\n","\n","test = pd.concat([test1,test2]).drop(['Pred'], axis=1)\n","test = merge_data(test)"]},{"cell_type":"markdown","metadata":{},"source":["## Model Training"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X = tourney.drop(['Season','TeamID1','TeamID2','result'], axis=1)\n","y = tourney[\"result\"]\n","s = tourney[\"Season\"]\n","\n","X_test = test.drop(['ID', 'Season','TeamID1','TeamID2'], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from ipywidgets import FloatProgress\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","from sklearn.experimental import enable_hist_gradient_boosting\n","from sklearn.ensemble import HistGradientBoostingRegressor, HistGradientBoostingClassifier, RandomForestClassifier\n","from sklearn.model_selection import KFold, GroupKFold\n","from sklearn.linear_model import LinearRegression, LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.metrics import log_loss\n","from tqdm.notebook import tqdm\n","import xgboost as xgb\n","\n","train = tourney\n","test = test\n","\n","xgb_params= {\n","        \"objective\": \"binary:logistic\",\n","        \"max_depth\": 2,\n","        \"learning_rate\": 0.1,\n","        \"colsample_bytree\": 0.8,\n","        \"subsample\": 0.8,\n","        \"min_child_weight\": 30,\n","        \"n_jobs\": 2,\n","        \"seed\": 2021,\n","        \"tree_method\": \"hist\",\n","        'predictor': 'cpu_predictor'\n","    }\n","\n","y = train[\"result\"]\n","s = train[\"Season\"]\n","X = train.drop(['Season','TeamID1','TeamID2','result'], axis=1)\n","\n","X_test = test.drop(['ID', 'Season','TeamID1','TeamID2'], axis=1)\n","\n","train_oof = np.zeros((X.shape[0],))\n","test_preds = 0\n","train_oof.shape\n","\n","NUM_FOLDS = 5\n","kf = GroupKFold(n_splits=NUM_FOLDS)\n","max_iter = 550\n","\n","for f, (train_ind, val_ind) in tqdm(enumerate(kf.split(X, y, s))):\n","        #print(f'Fold {f}')\n","        train_df, val_df = X.iloc[train_ind], X.iloc[val_ind]\n","        train_target, val_target = y.iloc[train_ind], y.iloc[val_ind]\n","        train_df_xgb = xgb.DMatrix(train_df, label=train_target)\n","        val_df_xgb = xgb.DMatrix(val_df, label=val_target)\n","        \n","        model = HistGradientBoostingClassifier(max_iter=max_iter, validation_fraction=None, learning_rate=0.01, max_depth=2, min_samples_leaf=32)\n","        model1 = RandomForestClassifier()\n","        model2 = LogisticRegression(C=1)\n","#         model3 = SVC(probability=True)\n","        model4 = xgb.train(xgb_params, train_df_xgb, 1000)\n","\n","        model =  model.fit(train_df, train_target)\n","        model1 =  model1.fit(train_df, train_target)\n","        model2 =  model2.fit(train_df, train_target)\n","#         model3 =  model3.fit(train_df, train_target)\n","          \n","#         temp_oof = model2.predict_proba(val_df)[:,1]\n","#         temp_test = model2.predict_proba(X_test)[:,1]\n","        \n","        temp_oof = (model.predict_proba(val_df)[:,1] + \\\n","                    model1.predict_proba(val_df)[:,1] + \\\n","                    model2.predict_proba(val_df)[:,1] + \\\n","#                     model3.predict_proba(val_df)[:,1] + \\\n","                    model4.predict(val_df_xgb)) / 4\n","        temp_test = (model.predict_proba(X_test)[:,1] \\\n","                     + model1.predict_proba(X_test)[:,1] \\\n","                     + model2.predict_proba(X_test)[:,1] \\\n","#                      + model3.predict_proba(X_test)[:,1] \\\n","                     + model4.predict(xgb.DMatrix(X_test))) / 4\n","\n","        train_oof[val_ind] = temp_oof\n","        test_preds += temp_test/NUM_FOLDS\n","        \n","        print(log_loss(val_target, temp_oof))\n","        \n","print('CV', log_loss(y, train_oof))        \n","np.save('train_oof', train_oof)\n","np.save('test_preds', test_preds)\n","\n","test = test\n","MSampleSubmission = pd.read_csv('../../data/2022/MSampleSubmissionStage2.csv')\n","\n","idx = test_preds.shape[0] //2\n","test_preds[idx:] = 1 - test_preds[idx:]\n","\n","pred = pd.concat([test.ID, pd.Series(test_preds)], axis=1).groupby('ID')[0]\\\n","        .mean().reset_index().rename(columns={0:'Pred'})\n","sub3 = MSampleSubmission.drop(['Pred'],axis=1).merge(pred, on='ID')\n","pred_3 = sub3['Pred']"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["0.5539459504635523"]},{"cell_type":"markdown","metadata":{},"source":["## Creating Submission File\n","\n","The second half of the test prediction need to be (1 - pred) as the team order was swapped. The predictions are averaged by ID after that."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["idx = test_preds.shape[0] //2\n","test_preds[idx:] = 1 - test_preds[idx:]\n","\n","pred = pd.concat([test.ID, pd.Series(test_preds)], axis=1).groupby('ID')[0]\\\n","        .mean().reset_index().rename(columns={0:'Pred'})\n","sub = MSampleSubmission.drop(['Pred'],axis=1).merge(pred, on='ID')\n","sub['Pred'] = sub['Pred'] * 0.3 + sub3['Pred'] * 0.7\n","sub.to_csv('submission.csv', index=False)\n","sub.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import sys\n","import os\n","folder_name = \"march_madness\"\n","BASE_DIR = os.path.abspath(\".\").split(folder_name)[0]+folder_name\n","#DATA_ROOT = os.path.join(BASE_DIR, \"data\")\n","sys.path.insert(0, BASE_DIR)\n","\n","from generate_bracket import build_bracket\n","\n","b = build_bracket(\n","    teamsPath=\"../../data/2022/MTeams.csv\",\n","    seedsPath=\"../../data/2022/MNCAATourneySeeds.csv\",\n","    slotsPath=\"../../data/2022/MNCAATourneySlots.csv\",\n","    submissionPath=\"submission.csv\",\n","    emptyBracketPath=\"../../empty_bracket/empty.jpg\",\n","    year=2022\n",")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":4}
