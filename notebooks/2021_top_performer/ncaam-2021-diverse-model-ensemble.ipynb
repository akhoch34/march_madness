{"cells":[{"cell_type":"markdown","metadata":{},"source":["# NCAAM 2021 - LGB w/ FE on three Datasets\n","\n","This notebook is copied from my notebook from NCAAM 2020. It shows LGB model training with feature engineering on three different datasets:\n","- MRegularSeasonCompactResults\n","- MRegularSeasonDetailedResults\n","- MMasseyOrdinals\n","\n","The engineered features are appended to MNCAATourneyCompactResults and then LGB will be trained on it.\n","\n","Only Season < 2015 is used for Stage1 training, so there is no leak on the test prediction."]},{"cell_type":"code","execution_count":8,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import numpy as np \n","import pandas as pd \n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import seaborn as sns; sns.set()\n","\n","from sklearn.model_selection import GroupKFold\n","from sklearn.metrics import log_loss\n","import lightgbm as lgb"]},{"cell_type":"markdown","metadata":{},"source":["For Stage 1, 2003 <= Season < 2015 will be used for the model training/validation and test preditions are calculated by that trained model. For Stage 2, Season >= 2003 will be used for  training."]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[],"source":["DATA_DIR = '../../data'\n","\n","STAGE_1 = False # This needs to be False when it's stage 2 "]},{"cell_type":"markdown","metadata":{},"source":["## FE on RegularSeasonCompactResults\n","\n","### Calculating Win %"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[],"source":["MRSCResults = pd.read_csv(DATA_DIR + '/MRegularSeasonCompactResults.csv')\n","\n","A_w = MRSCResults[MRSCResults.WLoc == 'A']\\\n","    .groupby(['Season','WTeamID'])['WTeamID'].count().to_frame()\\\n","    .rename(columns={\"WTeamID\": \"win_A\"})\n","N_w = MRSCResults[MRSCResults.WLoc == 'N']\\\n","    .groupby(['Season','WTeamID'])['WTeamID'].count().to_frame()\\\n","    .rename(columns={\"WTeamID\": \"win_N\"})\n","H_w = MRSCResults[MRSCResults.WLoc == 'H']\\\n","    .groupby(['Season','WTeamID'])['WTeamID'].count().to_frame()\\\n","    .rename(columns={\"WTeamID\": \"win_H\"})\n","win = A_w.join(N_w, how='outer').join(H_w, how='outer').fillna(0)\n","\n","H_l = MRSCResults[MRSCResults.WLoc == 'A']\\\n","    .groupby(['Season','LTeamID'])['LTeamID'].count().to_frame()\\\n","    .rename(columns={\"LTeamID\": \"lost_H\"})\n","N_l = MRSCResults[MRSCResults.WLoc == 'N']\\\n","    .groupby(['Season','LTeamID'])['LTeamID'].count().to_frame()\\\n","    .rename(columns={\"LTeamID\": \"lost_N\"})\n","A_l = MRSCResults[MRSCResults.WLoc == 'H']\\\n","    .groupby(['Season','LTeamID'])['LTeamID'].count().to_frame()\\\n","    .rename(columns={\"LTeamID\": \"lost_A\"})\n","lost = A_l.join(N_l, how='outer').join(H_l, how='outer').fillna(0)\n","\n","win.index = win.index.rename(['Season', 'TeamID'])\n","lost.index = lost.index.rename(['Season', 'TeamID'])\n","wl = win.join(lost, how='outer').reset_index()\n","wl['win_pct_A'] = wl['win_A'] / (wl['win_A'] + wl['lost_A'])\n","wl['win_pct_N'] = wl['win_N'] / (wl['win_N'] + wl['lost_N'])\n","wl['win_pct_H'] = wl['win_H'] / (wl['win_H'] + wl['lost_H'])\n","wl['win_pct_All'] = (wl['win_A'] + wl['win_N'] + wl['win_H']) / \\\n","    (wl['win_A'] + wl['win_N'] + wl['win_H'] + wl['lost_A']\\\n","     + wl['lost_N'] + wl['lost_H'])\n","\n","del A_w, N_w, H_w, H_l, N_l, A_l, win, lost"]},{"cell_type":"markdown","metadata":{},"source":["### Creating Score Features"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[],"source":["MRSCResults['relScore'] = MRSCResults.WScore - MRSCResults.LScore\n","\n","w_scr = MRSCResults.loc[:, ['Season', 'WTeamID', 'WScore', 'WLoc','relScore']]\n","w_scr.columns = ['Season', 'TeamID','Score','Loc','relScore']\n","l_scr = MRSCResults.loc[:, ['Season', 'LTeamID', 'LScore', 'WLoc','relScore']]\n","l_scr['WLoc'] = l_scr.WLoc.apply(lambda x: 'H' if x == 'A' else 'A' \\\n","                                 if x == 'H' else 'N')\n","l_scr['relScore'] = -1 * l_scr.relScore \n","l_scr.columns = ['Season', 'TeamID','Score','Loc','relScore']\n","wl_scr = pd.concat([w_scr,l_scr])\n","\n","A_scr = wl_scr[wl_scr.Loc == 'A'].groupby(['Season','TeamID'])\\\n","        ['Score','relScore'].mean()\\\n","        .rename(columns={\"Score\": \"Score_A\", \"relScore\": \"relScore_A\"})\n","N_scr = wl_scr[wl_scr.Loc == 'N'].groupby(['Season','TeamID'])\\\n","        ['Score','relScore'].mean()\\\n","        .rename(columns={\"Score\": \"Score_N\", \"relScore\": \"relScore_N\"})\n","H_scr = wl_scr[wl_scr.Loc == 'H'].groupby(['Season','TeamID'])\\\n","        ['Score','relScore'].mean()\\\n","        .rename(columns={\"Score\": \"Score_H\", \"relScore\": \"relScore_H\"})\n","All_scr = wl_scr.groupby(['Season','TeamID'])['Score','relScore']\\\n","    .mean().rename(columns={\"Score\": \"Score_All\", \"relScore\": \"relScore_All\"})\n","scr = A_scr.join(N_scr, how='outer').join(H_scr, how='outer')\\\n","    .join(All_scr, how='outer').fillna(0).reset_index()\n","\n","del w_scr, l_scr, wl_scr, A_scr, H_scr, N_scr, All_scr"]},{"cell_type":"markdown","metadata":{},"source":["## FE on MRegularSeasonDetailedResults"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[],"source":["MRSDetailedResults = pd.read_csv(DATA_DIR + '/MRegularSeasonDetailedResults.csv')\n","\n","w = MRSDetailedResults.loc[:, ['Season', 'WTeamID', 'WFGM','WFGA','WFGM3'\n","                               ,'WFGA3','WFTM','WFTA','WOR','WDR','WAst',\n","                               'WTO','WStl','WBlk','WPF']]\n","w.columns = ['Season', 'TeamID', 'FGM','FGA','FGM3','FGA3','FTM','FTA','OR','DR',\n","             'Ast','TO','Stl','Blk','PF']\n","l = MRSDetailedResults.loc[:, ['Season', 'LTeamID', 'LFGM','LFGA','LFGM3',\n","                               'LFGA3','LFTM','LFTA','LOR','LDR','LAst',\n","                               'LTO','LStl','LBlk','LPF']]\n","l.columns = ['Season', 'TeamID', 'FGM','FGA','FGM3','FGA3','FTM','FTA','OR','DR',\n","             'Ast','TO','Stl','Blk','PF']\n","\n","detail = pd.concat([w,l])\n","detail['goal_rate'] = detail.FGM / detail.FGA \n","detail['3p_goal_rate'] = detail.FGM3 / detail.FGA3  \n","detail['ft_goal_rate'] = detail.FTM  / detail.FTA  \n","\n","dt = detail.groupby(['Season','TeamID'])['FGM','FGA','FGM3','FGA3','FTM','FTA',\n","                                         'OR','DR','Ast','TO','Stl','Blk','PF',\n","                                          'goal_rate', '3p_goal_rate',\n","                                         'ft_goal_rate']\\\n","                                        .mean().fillna(0).reset_index()\n","\n","del w, l, detail"]},{"cell_type":"markdown","metadata":{},"source":["## FE on MMasseyOrdinals\n","\n","Using only MOR for now."]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[],"source":["MMOrdinals = pd.read_csv(DATA_DIR + '/MMasseyOrdinals.csv')\n","\n","MOR_127_128 = MMOrdinals[(MMOrdinals.SystemName == 'MOR') & \\\n","                ((MMOrdinals.RankingDayNum == 127) \\\n","                 | (MMOrdinals.RankingDayNum == 128))]\\\n","                [['Season','TeamID','OrdinalRank']]\n","MOR_50_51 = MMOrdinals[(MMOrdinals.SystemName == 'MOR') & \\\n","                ((MMOrdinals.RankingDayNum == 50) \\\n","                 | (MMOrdinals.RankingDayNum == 51))]\\\n","                [['Season','TeamID','OrdinalRank']]\n","MOR_15_16 = MMOrdinals[(MMOrdinals.SystemName == 'MOR') & \\\n","                ((MMOrdinals.RankingDayNum == 15) \\\n","                 | (MMOrdinals.RankingDayNum == 16))]\\\n","                [['Season','TeamID','OrdinalRank']]\n","\n","MOR_127_128 = MOR_127_128.rename(columns={'OrdinalRank':'OrdinalRank_127_128'})\n","MOR_50_51 = MOR_50_51.rename(columns={'OrdinalRank':'OrdinalRank_50_51'})\n","MOR_15_16 = MOR_15_16.rename(columns={'OrdinalRank':'OrdinalRank_15_16'})\n","\n","MOR = MOR_127_128.merge(MOR_50_51, how='left', on=['Season','TeamID'])\\\n","        .merge(MOR_15_16, how='left', on=['Season','TeamID'])\n","\n","## normalizing Rank values by its season maxium as it varies by seasons\n","MOR_max = MOR.groupby('Season')['OrdinalRank_127_128','OrdinalRank_50_51',\n","                                'OrdinalRank_15_16'].max().reset_index()\n","MOR_max.columns = ['Season', 'maxRank_127_128', 'maxRank_50_51', 'maxRank_15_16']\n","\n","MOR_tmp = MMOrdinals[(MMOrdinals.SystemName == 'MOR') \\\n","                     & (MMOrdinals.RankingDayNum < 133)]\n","MOR_stats = MOR_tmp.groupby(['Season','TeamID'])['OrdinalRank']\\\n","            .agg(['max','min','std','mean']).reset_index()\n","MOR_stats.columns = ['Season','TeamID','RankMax','RankMin','RankStd','RankMean']\n","\n","MOR = MOR.merge(MOR_max, how='left', on='Season')\\\n","        .merge(MOR_stats, how='left', on=['Season','TeamID'])\n","MOR['OrdinalRank_127_128'] = MOR['OrdinalRank_127_128'] / MOR['maxRank_127_128']\n","MOR['OrdinalRank_50_51'] = MOR['OrdinalRank_50_51'] / MOR['maxRank_50_51']\n","MOR['OrdinalRank_15_16'] = MOR['OrdinalRank_15_16'] / MOR['maxRank_15_16']\n","MOR['RankTrans_50_51_to_127_128'] = MOR['OrdinalRank_127_128'] \\\n","                                    - MOR['OrdinalRank_50_51']\n","MOR['RankTrans_15_16_to_127_128'] = MOR['OrdinalRank_127_128'] \\\n","                                    - MOR['OrdinalRank_15_16']\n","\n","# MOR['RankMax'] = MOR['RankMax'] / MOR['maxRank_127_128']\n","# MOR['RankMin'] = MOR['RankMin'] / MOR['maxRank_127_128']\n","# MOR['RankStd'] = MOR['RankStd'] / MOR['maxRank_127_128']\n","# MOR['RankMean'] = MOR['RankMean'] / MOR['maxRank_127_128']\n","\n","MOR.drop(['OrdinalRank_50_51','OrdinalRank_15_16', 'maxRank_50_51'\n","          ,'maxRank_15_16'],axis=1, inplace=True)\n","\n","del MOR_127_128, MOR_50_51, MOR_15_16, MOR_max, MOR_tmp, MOR_stats"]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[],"source":["# Checking availability on RankingDayNum by SystemName \n","\n","#pd.options.display.max_columns=100\n","#tmp = MMasseyOrdinals[(MMasseyOrdinals.SystemName == 'MOR')]\n","#pd.crosstab(tmp.Season, tmp.RankingDayNum)"]},{"cell_type":"markdown","metadata":{},"source":["## FE on MNCAATourneySeeds\n","\n","Seed didn't improve the score, so it's not used."]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[],"source":["# MNCAATourneySeeds = pd.read_csv(DATA_DIR + '/MDataFiles_Stage1/MNCAATourneySeeds.csv')\n","# MNCAATourneySeeds['seed_num'] =  MNCAATourneySeeds.Seed.apply(lambda x: int(x[1:3]))\n","# MNCAATourneySeeds.drop('Seed', axis=1, inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["Duplicating each data with changing column names to be matched to 'WTeamID' and 'LTeamID' in Tourney dataset"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[],"source":["wl_1 = wl.loc[:,['Season','TeamID','win_pct_A','win_pct_N',\n","                 'win_pct_H','win_pct_All']]\n","wl_1.columns = [str(col) + '_1' if col not in ['Season','TeamID'] \\\n","                else str(col) for col in wl_1.columns ]\n","\n","wl_2 = wl.loc[:,['Season','TeamID','win_pct_A','win_pct_N',\n","                 'win_pct_H','win_pct_All']]\n","wl_2.columns = [str(col) + '_2' if col not in ['Season','TeamID'] \\\n","                else str(col) for col in wl_2.columns ]\n","\n","scr_1 = scr.copy()\n","scr_1.columns = [str(col) + '_1' if col not in ['Season','TeamID'] \\\n","                 else str(col) for col in scr_1.columns ]\n","\n","scr_2 = scr.copy()\n","scr_2.columns = [str(col) + '_2' if col not in ['Season','TeamID'] \\\n","                 else str(col) for col in scr_2.columns ]\n","\n","dt_1 = dt.copy()\n","dt_1.columns = [str(col) + '_1' if col not in ['Season','TeamID'] \\\n","                else str(col) for col in dt_1.columns ]\n","\n","dt_2 = dt.copy()\n","dt_2.columns = [str(col) + '_2' if col not in ['Season','TeamID'] \\\n","                else str(col) for col in dt_2.columns ]\n","\n","MOR_1 = MOR.copy()\n","MOR_1.columns = [str(col) + '_1' if col not in ['Season','TeamID'] \\\n","                 else str(col) for col in MOR_1.columns ]\n","\n","MOR_2 = MOR.copy()\n","MOR_2.columns = [str(col) + '_2' if col not in ['Season','TeamID'] \\\n","                 else str(col) for col in MOR_2.columns ]"]},{"cell_type":"markdown","metadata":{},"source":["## Loading MNCAATourneyCompactResults\n","\n","This dataset will be the base dataset for the model training"]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[],"source":["TCResults = pd.read_csv(DATA_DIR + '/MNCAATourneyCompactResults.csv')\n","\n","tourney1 = TCResults.loc[:, ['Season','WTeamID','LTeamID']]\n","tourney1.columns = ['Season','TeamID1','TeamID2']\n","tourney1['result'] = 1\n","\n","tourney2 = TCResults.loc[:, ['Season','LTeamID','WTeamID']]\n","tourney2.columns = ['Season','TeamID1','TeamID2']\n","tourney2['result'] = 0\n","\n","tourney = pd.concat([tourney1, tourney2])\n","del tourney1, tourney2"]},{"cell_type":"markdown","metadata":{},"source":["### Merging engineered features to Tourney dataset"]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true},"outputs":[],"source":["def merge_data(df):\n","\n","    df = df.merge(wl_1, how='left', left_on=['Season','TeamID1'],\n","                  right_on=['Season','TeamID'])\n","    df = df.merge(wl_2, how='left', left_on=['Season','TeamID2'],\n","                  right_on=['Season','TeamID'])\n","    df = df.drop(['TeamID_x','TeamID_y'], axis=1)\n","\n","\n","    df = df.merge(scr_1, how='left', left_on=['Season','TeamID1'],\n","                  right_on=['Season','TeamID'])\n","    df = df.merge(scr_2, how='left', left_on=['Season','TeamID2'],\n","                  right_on=['Season','TeamID'])\n","    df = df.drop(['TeamID_x','TeamID_y'], axis=1)\n","\n","    # df['win_pct_A_diff'] = df['win_pct_A_1'] - df['win_pct_A_2']\n","    # df['win_pct_N_diff'] = df['win_pct_N_1'] - df['win_pct_N_2']\n","    # df['win_pct_H_diff'] = df['win_pct_H_1'] - df['win_pct_H_2']\n","#     df['win_pct_All_diff'] = df['win_pct_All_1'] - df['win_pct_All_2']\n","\n","    # df['Score_A_diff'] = df['Score_A_1'] - df['Score_A_2']\n","    # df['Score_N_diff'] = df['Score_N_1'] - df['Score_N_2']\n","    # df['Score_H_diff'] = df['Score_H_1'] - df['Score_H_2']\n","    # df['Score_All_diff'] = df['Score_All_1'] - df['Score_All_2']\n","\n","    # df['relScore_A_diff'] = df['relScore_A_1'] - df['relScore_A_2']\n","    # df['relScore_N_diff'] = df['relScore_N_1'] - df['relScore_N_2']\n","    # df['relScore_H_diff'] = df['relScore_H_1'] - df['relScore_H_2']\n","#     df['relScore_All_diff'] = df['relScore_All_1'] - df['relScore_All_2']\n","\n","    df = df.merge(dt_1, how='left', left_on=['Season','TeamID1'],\n","                  right_on=['Season','TeamID'])\n","    df = df.merge(dt_2, how='left', left_on=['Season','TeamID2'],\n","                  right_on=['Season','TeamID'])\n","    \n","    df = df.drop(['TeamID_x','TeamID_y'], axis=1)\n","\n","    df = df.merge(MOR_1, how='left', left_on=['Season','TeamID1'],\n","                  right_on=['Season','TeamID'])\n","    df = df.merge(MOR_2, how='left', left_on=['Season','TeamID2'],\n","                  right_on=['Season','TeamID'])\n","    df = df.drop(['TeamID_x','TeamID_y'], axis=1)\n","\n","    df['OrdinalRank_127_128_diff'] = df['OrdinalRank_127_128_1'] \\\n","        - df['OrdinalRank_127_128_2']\n","    \n","    df['magic1'] = df['OrdinalRank_127_128_diff'] - df['RankMean_1']\n","    df['magic2'] = df['RankMean_1'] - df['RankMean_2']\n","    df['magic3'] = df['OrdinalRank_127_128_diff'] - df['RankMean_2']\n","    \n","    df['magic11'] = df['OrdinalRank_127_128_diff'] * df['RankMean_1']\n","    df['magic21'] = df['RankMean_1'] * df['RankMean_2']\n","    df['magic31'] = df['OrdinalRank_127_128_diff'] * df['RankMean_2']\n","    \n","    df['magic12'] = df['OrdinalRank_127_128_diff'] / df['RankMean_1']\n","    df['magic22'] = df['RankMean_1'] / df['RankMean_2']\n","    df['magic32'] = df['OrdinalRank_127_128_diff'] / df['RankMean_2']\n","\n","    df = df.fillna(-1)\n","    \n","    for col in df.columns:\n","        if (df[col] == np.inf).any() or (df[col] == -np.inf).any():\n","            df[col][(df[col] == np.inf) | (df[col] == -np.inf)] = -1\n","    \n","    return df\n","\n","tourney = merge_data(tourney)\n","tourney = tourney.loc[tourney.Season >= 2003,:].reset_index(drop=True)\n","\n","if STAGE_1:\n","    tourney = tourney.loc[tourney.Season < 2015, :]"]},{"cell_type":"markdown","metadata":{},"source":["## Loading Submission Dataset\n","Duplicating each ID with swapping TeamIDs. Predictions will be averaged by ID to get better performance."]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[],"source":["if STAGE_1:\n","    MSampleSubmission = pd.read_csv(DATA_DIR + '/MSampleSubmissionStage1.csv')\n","else:\n","    MSampleSubmission = pd.read_csv(DATA_DIR + '/MSampleSubmissionStage2.csv') # put stage 2 submission file link here\n","\n","test1 = MSampleSubmission.copy()\n","test1['Season'] = test1.ID.apply(lambda x: int(x[0:4]))\n","test1['TeamID1'] = test1.ID.apply(lambda x: int(x[5:9]))\n","test1['TeamID2'] = test1.ID.apply(lambda x: int(x[10:14]))\n","\n","test2 = MSampleSubmission.copy()\n","test2['Season'] = test2.ID.apply(lambda x: int(x[0:4]))\n","test2['TeamID1'] = test2.ID.apply(lambda x: int(x[10:14]))\n","test2['TeamID2'] = test2.ID.apply(lambda x: int(x[5:9]))\n","\n","test = pd.concat([test1,test2]).drop(['Pred'], axis=1)\n","test = merge_data(test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Model Training"]},{"cell_type":"code","execution_count":20,"metadata":{"trusted":true},"outputs":[],"source":["X = tourney.drop(['Season','TeamID1','TeamID2','result'], axis=1)\n","y = tourney[\"result\"]\n","s = tourney[\"Season\"]\n","\n","X_test = test.drop(['ID', 'Season','TeamID1','TeamID2'], axis=1)"]},{"cell_type":"code","execution_count":21,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["2011    134\n","2012    134\n","2018    134\n","2017    134\n","2016    134\n","2015    134\n","2014    134\n","2013    134\n","2019    134\n","2004    128\n","2010    128\n","2009    128\n","2008    128\n","2007    128\n","2006    128\n","2005    128\n","2003    128\n","Name: Season, dtype: int64"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["s.value_counts()"]},{"cell_type":"code","execution_count":22,"metadata":{"trusted":true},"outputs":[],"source":["def model_training(X, y, cv, groups, params, metric, early_stopping=10, \\\n","    plt_iter=True, X_test=[], cat_features=[]):\n","\n","    feature_importance = pd.DataFrame()\n","    val_scores=[]\n","    train_evals=[]\n","    valid_evals=[]\n","\n","    if len(X_test) > 0:\n","        test_pred=np.zeros(len(X_test))\n","\n","    for idx, (train_index, val_index) in enumerate(cv.split(X, y, groups)):\n","\n","        print(\"###### fold %d ######\" % (idx+1))\n","        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n","        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n","\n","        model = lgb.LGBMClassifier(**params)\n","\n","        model.fit(X_train, y_train,\n","                  eval_set=[(X_train, y_train), (X_val, y_val)],\n","                  early_stopping_rounds=early_stopping,\n","                  verbose=20\n","                  #categorical_feature=list(cate_ft_lst),\n","                  )\n","\n","        val_scores.append(model.best_score_['valid_1'][metric])\n","        train_evals.append(model.evals_result_['training'][metric])\n","        valid_evals.append(model.evals_result_['valid_1'][metric])\n","\n","        if len(X_test) > 0:\n","            test_pred = test_pred + model.predict_proba(X_test, num_iteration=model.best_iteration_)[:,1]\n","\n","        fold_importance = pd.DataFrame()\n","        fold_importance[\"feature\"] = X_train.columns\n","        fold_importance[\"importance\"] = model.feature_importances_\n","        fold_importance[\"fold\"] = idx+1\n","        feature_importance = pd.concat([feature_importance, fold_importance]\n","                                       , axis=0)\n","\n","    if plt_iter:\n","        \n","        fig, axs = plt.subplots(2, 2, figsize=(9,6))\n","        \n","        for i, ax in enumerate(axs.flatten()):\n","            ax.plot(train_evals[i], label='training')\n","            ax.plot(valid_evals[i], label='validation')\n","            ax.set(xlabel='interations', ylabel=f'{metric}')\n","            ax.set_title(f'fold {i+1}', fontsize=12)\n","            ax.legend(loc='upper right', prop={'size': 9})\n","        fig.tight_layout()\n","        plt.show()\n","    \n","    print('### CV scores by fold ###')\n","    for i in range(cv.get_n_splits(X)):\n","        print(f'fold {i+1}: {val_scores[i]:.4f}')\n","    print('CV mean score: {0:.4f}, std: {1:.4f}.'\\\n","          .format(np.mean(val_scores), np.std(val_scores)))\n","    \n","    feature_importance = feature_importance[[\"feature\", \"importance\"]]\\\n","                         .groupby(\"feature\").mean().sort_values(\n","                         by=\"importance\", ascending=False)\n","    feature_importance.reset_index(inplace=True)\n","\n","    if len(X_test) > 0:\n","        test_pred = test_pred / cv.get_n_splits(X)\n","        return feature_importance, test_pred\n","    else:\n","        return feature_importance"]},{"cell_type":"code","execution_count":23,"metadata":{"trusted":true},"outputs":[],"source":["lgb_params = {'objective': 'binary',\n","              'metric': 'binary_logloss',\n","              'boosting': 'gbdt',\n","              'num_leaves': 31,\n","              'feature_fraction': 0.8,\n","              'bagging_fraction': 0.8,\n","              'bagging_freq': 5,\n","              'learning_rate': 0.1,\n","              'n_estimators': 1000,\n","}"]},{"cell_type":"markdown","metadata":{},"source":["Using GroupKFold by Season"]},{"cell_type":"code","execution_count":24,"metadata":{"trusted":true},"outputs":[],"source":["N_FOLDS = 10"]},{"cell_type":"code","execution_count":25,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["###### fold 1 ######\n"]},{"ename":"AttributeError","evalue":"module 'lightgbm' has no attribute 'LGBMClassifier'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","File \u001b[0;32m<timed exec>:4\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36mmodel_training\u001b[0;34m(X, y, cv, groups, params, metric, early_stopping, plt_iter, X_test, cat_features)\u001b[0m\n\u001b[1;32m     15\u001b[0m X_train, X_val \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc[train_index], X\u001b[38;5;241m.\u001b[39miloc[val_index]\n\u001b[1;32m     16\u001b[0m y_train, y_val \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[train_index], y\u001b[38;5;241m.\u001b[39miloc[val_index]\n\u001b[0;32m---> 18\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBMClassifier\u001b[49m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train,\n\u001b[1;32m     21\u001b[0m           eval_set\u001b[38;5;241m=\u001b[39m[(X_train, y_train), (X_val, y_val)],\n\u001b[1;32m     22\u001b[0m           early_stopping_rounds\u001b[38;5;241m=\u001b[39mearly_stopping,\n\u001b[1;32m     23\u001b[0m           verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m\n\u001b[1;32m     24\u001b[0m           \u001b[38;5;66;03m#categorical_feature=list(cate_ft_lst),\u001b[39;00m\n\u001b[1;32m     25\u001b[0m           )\n\u001b[1;32m     27\u001b[0m val_scores\u001b[38;5;241m.\u001b[39mappend(model\u001b[38;5;241m.\u001b[39mbest_score_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid_1\u001b[39m\u001b[38;5;124m'\u001b[39m][metric])\n","\u001b[0;31mAttributeError\u001b[0m: module 'lightgbm' has no attribute 'LGBMClassifier'"]}],"source":["%%time\n","group_kfold = GroupKFold(n_splits=N_FOLDS)\n","\n","feature_importance, test_pred = \\\n","    model_training(X, y, group_kfold, s, lgb_params, \n","    'binary_logloss', plt_iter=True, X_test=X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'feature_importance' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m));\n\u001b[0;32m----> 2\u001b[0m sns\u001b[38;5;241m.\u001b[39mbarplot(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimportance\u001b[39m\u001b[38;5;124m\"\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m\"\u001b[39m, data\u001b[38;5;241m=\u001b[39m\u001b[43mfeature_importance\u001b[49m[:\u001b[38;5;241m30\u001b[39m])\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature Importnace\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'feature_importance' is not defined"]},{"data":{"text/plain":["<Figure size 720x720 with 0 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.figure(figsize=(10, 10));\n","sns.barplot(x=\"importance\", y=\"feature\", data=feature_importance[:30])\n","plt.title('Feature Importnace')"]},{"cell_type":"markdown","metadata":{},"source":["# 2nd model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# # https://www.kaggle.com/joseleiva/massey-s-ordinal-s-ordinals\n","\n","# import numpy as np\n","# import pandas as pd\n","\n","# inp = '../input/ncaam-march-mania-2021/'\n","# season_df = pd.read_csv(inp+'MRegularSeasonCompactResults.csv')\n","# tourney_df = pd.read_csv(inp+'MNCAATourneyCompactResults.csv')\n","# ordinals_df = pd.read_csv(inp+'MMasseyOrdinals.csv').rename(columns={'RankingDayNum':'DayNum'})\n","\n","# # Get the last available data from each system previous to the tournament\n","# ordinals_df = ordinals_df.groupby(['SystemName','Season','TeamID']).last().reset_index()\n","\n","# # Add winner's ordinals\n","# games_df = tourney_df.merge(ordinals_df,left_on=['Season','WTeamID'],\n","#                           right_on=['Season','TeamID'])\n","# games_df.head()\n","# # Then add losser's ordinals\n","# games_df = games_df.merge(ordinals_df,left_on=['Season','LTeamID','SystemName'],\n","#                           right_on=['Season','TeamID','SystemName'],\n","#                           suffixes = ['W','L'])\n","\n","# ## Add column with 1 if result is correct\n","# games_df = games_df.drop(labels=['TeamIDW','TeamIDL'],axis=1)\n","# games_df['prediction'] = (games_df.OrdinalRankW<games_df.OrdinalRankL).astype(int)\n","# results_by_system = games_df.groupby('SystemName').agg({'prediction':('mean','count')})\n","\n","# games_df['Wrating'] = 100-4*np.log(games_df['OrdinalRankW']+1)-games_df['OrdinalRankW']/22\n","# games_df['Lrating'] = 100-4*np.log(games_df['OrdinalRankL']+1)-games_df['OrdinalRankL']/22\n","# games_df['prob'] = 1/(1+10**((games_df['Lrating']-games_df['Wrating'])/15))\n","# loss_results = games_df[games_df.Season>=2015].groupby('SystemName')['prob'].agg([('loss',lambda p: -np.mean(np.log(p))),('count','count')])\n","\n","# ref_system = 'POM'\n","# ordinals_df['Rating']= 100-4*np.log(ordinals_df['OrdinalRank']+1)-ordinals_df['OrdinalRank']/22\n","# ordinals_df = ordinals_df[ordinals_df.SystemName==ref_system]\n","\n","# # Get submission file\n","# sub_df = pd.read_csv(inp+'MSampleSubmissionStage1.csv')\n","# sub_df['Season'] = sub_df['ID'].map(lambda x: int(x.split('_')[0]))\n","# sub_df['Team1'] = sub_df['ID'].map(lambda x: int(x.split('_')[1]))\n","# sub_df['Team2'] = sub_df['ID'].map(lambda x: int(x.split('_')[2]))\n","# sub_df = sub_df.merge(ordinals_df[['Season','TeamID','Rating']], how='left', left_on = ['Season','Team1'], right_on = ['Season','TeamID'])\n","# sub_df = sub_df.merge(ordinals_df[['Season','TeamID','Rating']], how='left', left_on = ['Season','Team2'], right_on = ['Season','TeamID'], suffixes=['W','L'])"]},{"cell_type":"markdown","metadata":{},"source":["# 3rd model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[{"ename":"XGBoostError","evalue":"\nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): [\"dlopen(/Users/conorohalloran/Documents/ChiFinesse/march_madness/.venv/lib/python3.9/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\\n  Referenced from: /Users/conorohalloran/Documents/ChiFinesse/march_madness/.venv/lib/python3.9/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\"]\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)","Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m log_loss\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnotebook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[1;32m     14\u001b[0m train \u001b[38;5;241m=\u001b[39m tourney\n\u001b[1;32m     15\u001b[0m test \u001b[38;5;241m=\u001b[39m test\n","File \u001b[0;32m~/Documents/ChiFinesse/march_madness/.venv/lib/python3.9/site-packages/xgboost/__init__.py:9\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"XGBoost: eXtreme Gradient Boosting library.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mContributors: https://github.com/dmlc/xgboost/blob/master/CONTRIBUTORS.md\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DMatrix, DeviceQuantileDMatrix, Booster, DataIter\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train, cv\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rabit  \u001b[38;5;66;03m# noqa\u001b[39;00m\n","File \u001b[0;32m~/Documents/ChiFinesse/march_madness/.venv/lib/python3.9/site-packages/xgboost/core.py:203\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m# load the XGBoost library globally\u001b[39;00m\n\u001b[0;32m--> 203\u001b[0m _LIB \u001b[38;5;241m=\u001b[39m \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_call\u001b[39m(ret):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m    This function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;124;03m        return value from API calls\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n","File \u001b[0;32m~/Documents/ChiFinesse/march_madness/.venv/lib/python3.9/site-packages/xgboost/core.py:181\u001b[0m, in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib_success:\n\u001b[1;32m    180\u001b[0m         libname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(lib_paths[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 181\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(\n\u001b[1;32m    182\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124mXGBoost Library (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlibname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) could not be loaded.\u001b[39m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124mLikely causes:\u001b[39m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;124m  * OpenMP runtime is not installed\u001b[39m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124m    - vcomp140.dll or libgomp-1.dll for Windows\u001b[39m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124m    - libomp.dylib for Mac OSX\u001b[39m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124m    - libgomp.so for Linux and other UNIX-like OSes\u001b[39m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124m    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\u001b[39m\n\u001b[1;32m    190\u001b[0m \n\u001b[1;32m    191\u001b[0m \u001b[38;5;124m  * You are running 32-bit Python on a 64-bit OS\u001b[39m\n\u001b[1;32m    192\u001b[0m \n\u001b[1;32m    193\u001b[0m \u001b[38;5;124mError message(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos_error_list\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[1;32m    195\u001b[0m     lib\u001b[38;5;241m.\u001b[39mXGBGetLastError\u001b[38;5;241m.\u001b[39mrestype \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_char_p\n\u001b[1;32m    196\u001b[0m     lib\u001b[38;5;241m.\u001b[39mcallback \u001b[38;5;241m=\u001b[39m _get_log_callback_func()\n","\u001b[0;31mXGBoostError\u001b[0m: \nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): [\"dlopen(/Users/conorohalloran/Documents/ChiFinesse/march_madness/.venv/lib/python3.9/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\\n  Referenced from: /Users/conorohalloran/Documents/ChiFinesse/march_madness/.venv/lib/python3.9/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\"]\n"]}],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","import numpy as np\n","import pandas as pd\n","from sklearn.experimental import enable_hist_gradient_boosting\n","from sklearn.ensemble import HistGradientBoostingRegressor, HistGradientBoostingClassifier, RandomForestClassifier\n","from sklearn.model_selection import KFold, GroupKFold\n","from sklearn.linear_model import LinearRegression, LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.metrics import log_loss\n","from tqdm.notebook import tqdm\n","import xgboost as xgb\n","\n","train = tourney\n","test = test\n","\n","xgb_params= {\n","        \"objective\": \"binary:logistic\",\n","        \"max_depth\": 2,\n","        \"learning_rate\": 0.1,\n","        \"colsample_bytree\": 0.8,\n","        \"subsample\": 0.8,\n","        #\"reg_alpha\" : 0,\n","        \"min_child_weight\": 30,\n","        \"n_jobs\": 2,\n","        \"seed\": 2021,\n","        'tree_method': \"gpu_hist\",\n","        \"gpu_id\": 0,\n","        'predictor': 'gpu_predictor'\n","    }\n","\n","y = train[\"result\"]\n","s = train[\"Season\"]\n","X = train.drop(['Season','TeamID1','TeamID2','result'], axis=1)\n","\n","X_test = test.drop(['ID', 'Season','TeamID1','TeamID2'], axis=1)\n","\n","train_oof = np.zeros((X.shape[0],))\n","test_preds = 0\n","train_oof.shape\n","\n","NUM_FOLDS = 5\n","kf = GroupKFold(n_splits=NUM_FOLDS)\n","max_iter = 550\n","\n","for f, (train_ind, val_ind) in tqdm(enumerate(kf.split(X, y, s))):\n","        #print(f'Fold {f}')\n","        train_df, val_df = X.iloc[train_ind], X.iloc[val_ind]\n","        train_target, val_target = y.iloc[train_ind], y.iloc[val_ind]\n","        train_df_xgb = xgb.DMatrix(train_df, label=train_target)\n","        val_df_xgb = xgb.DMatrix(val_df, label=val_target)\n","        \n","        model = HistGradientBoostingClassifier(max_iter=max_iter, validation_fraction=None, learning_rate=0.01, max_depth=2, min_samples_leaf=32)\n","        model1 = RandomForestClassifier()\n","        model2 = LogisticRegression(C=1)\n","#         model3 = SVC(probability=True)\n","        model4 = xgb.train(xgb_params, train_df_xgb, 1000)\n","\n","        model =  model.fit(train_df, train_target)\n","        model1 =  model1.fit(train_df, train_target)\n","        model2 =  model2.fit(train_df, train_target)\n","#         model3 =  model3.fit(train_df, train_target)\n","          \n","#         temp_oof = model2.predict_proba(val_df)[:,1]\n","#         temp_test = model2.predict_proba(X_test)[:,1]\n","        \n","        temp_oof = (model.predict_proba(val_df)[:,1] + \\\n","                    model1.predict_proba(val_df)[:,1] + \\\n","                    model2.predict_proba(val_df)[:,1] + \\\n","#                     model3.predict_proba(val_df)[:,1] + \\\n","                    model4.predict(val_df_xgb)) / 4\n","        temp_test = (model.predict_proba(X_test)[:,1] \\\n","                     + model1.predict_proba(X_test)[:,1] \\\n","                     + model2.predict_proba(X_test)[:,1] \\\n","#                      + model3.predict_proba(X_test)[:,1] \\\n","                     + model4.predict(xgb.DMatrix(X_test))) / 4\n","\n","        train_oof[val_ind] = temp_oof\n","        test_preds += temp_test/NUM_FOLDS\n","        \n","        print(log_loss(val_target, temp_oof))\n","        \n","print('CV', log_loss(y, train_oof))        \n","np.save('train_oof', train_oof)\n","np.save('test_preds', test_preds)\n","\n","test = test\n","MSampleSubmission = pd.read_csv('../input/ncaam-march-mania-2021/MDataFiles_Stage2/MSampleSubmissionStage2.csv')\n","\n","idx = test_preds.shape[0] //2\n","test_preds[idx:] = 1 - test_preds[idx:]\n","\n","pred = pd.concat([test.ID, pd.Series(test_preds)], axis=1).groupby('ID')[0]\\\n","        .mean().reset_index().rename(columns={0:'Pred'})\n","sub3 = MSampleSubmission.drop(['Pred'],axis=1).merge(pred, on='ID')\n","pred_3 = sub3['Pred']"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["0.5539459504635523"]},{"cell_type":"markdown","metadata":{},"source":["## Creating Submission File\n","\n","The second half of the test prediction need to be (1 - pred) as the team order was swapped. The predictions are averaged by ID after that."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["idx = test_pred.shape[0] //2\n","test_pred[idx:] = 1 - test_pred[idx:]\n","\n","pred = pd.concat([test.ID, pd.Series(test_pred)], axis=1).groupby('ID')[0]\\\n","        .mean().reset_index().rename(columns={0:'Pred'})\n","sub = MSampleSubmission.drop(['Pred'],axis=1).merge(pred, on='ID')\n","sub['Pred'] = sub['Pred'] * 0.3 + sub3['Pred'] * 0.7\n","sub.to_csv('submission.csv', index=False)\n","sub.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Calculating Test Score Locally"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["if STAGE_1:\n","    rslt = pd.DataFrame()\n","    TCResults_s = TCResults.loc[TCResults.Season >= 2015,:]\n","    rslt['season'] = TCResults_s.Season\n","    rslt['team1'] = TCResults_s.apply(lambda x: x.WTeamID \\\n","                                      if x.WTeamID < x.LTeamID else x.LTeamID\n","                                      , axis=1)\n","    rslt['team2'] = TCResults_s.apply(lambda x: x.WTeamID \\\n","                                      if x.WTeamID > x.LTeamID else x.LTeamID\n","                                      , axis=1)\n","    rslt['wl'] = TCResults_s.apply(lambda x: 1 if x.WTeamID < x.LTeamID else 0\n","                                   , axis=1)\n","    rslt['ID'] = rslt.apply(lambda x: str(x.season) + '_' + str(x.team1) \\\n","                            + '_' + str(x.team2), axis=1)\n","    sub2 = sub.merge(rslt.loc[:,['ID','wl']], how='inner', on='ID')\n","\n","    preds = []\n","    for i in sub2.Pred:\n","        preds.append([1-i, i])\n","\n","    print('Test logloss is {:.5f}'.format(log_loss(sub2.wl.values, preds)))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["0.51971"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":4}
